description,f1,precision,recall
logistic regression with tfidf and spacy tokenization,0.7620111731843576,0.8061465721040191,0.7224576271186439
Bi-LSTM,0.8080357142857143,0.8537735849056604,0.7669491525423728
roberta-base,0.9087221095334684,0.8715953307392996,0.9491525423728814
albert-base-v2,0.8921465968586386,0.8819875776397516,0.902542372881356
BERTweet,0.8995815899581591,0.8884297520661157,0.9110169491525424
roberta-base mean of all tokens from last layer,0.8961303462321792,0.8627450980392157,0.9322033898305084
roberta-base max of all tokens from last layer,0.8953140578265205,0.8455743879472694,0.951271186440678
roberta-base mean of all tokens from all layers,0.9076142131979696,0.8713450292397661,0.9470338983050848
roberta-base max of all tokens from all layers,0.9064748201438848,0.8802395209580839,0.934322033898305
roberta-base mean of all tokens from layers 9_10_11_12,0.9083585095669688,0.8656429942418427,0.9555084745762712
